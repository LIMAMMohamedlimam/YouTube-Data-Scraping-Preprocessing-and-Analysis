{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tm\n",
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup \n",
    "import xlsxwriter as xlwr \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the url of the channel whose data you want to fetch \n",
    "urls = [ \n",
    "\t    'https://www.youtube.com/@MrBeast/videos'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = 0\n",
    "driver = webdriver.Chrome() \n",
    "for url in urls:\n",
    "    print(url) \n",
    "    driver.get('{}/videos?view=0&sort=p&flow=grid'.format(url)) \n",
    "    while times < 10: \n",
    "        tm.sleep(1)    \n",
    "        driver.execute_script( \n",
    "            \"window.scrollTo(0, document.documentElement.scrollHeight);\") \n",
    "        times += 1\n",
    "    content = driver.page_source.encode('utf-8').strip() \n",
    "    soup = BeautifulSoup(content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title \n",
    "titles = soup.findAll('yt-formatted-string', class_ = 'style-scope ytd-rich-grid-media') \n",
    "t =[] \n",
    "for i in range(len(titles)): \n",
    "    if i%2 == 0:\n",
    "        t.append(titles[i].text) \n",
    "    else:\n",
    "        continue\n",
    "  \n",
    "#Views \n",
    "views = soup.findAll('span', class_=\"inline-metadata-item style-scope ytd-video-meta-block\") \n",
    "v = [] \n",
    "count = 0\n",
    "for i in range(len(views)): \n",
    "    if i%2 == 0: \n",
    "        v.append(views[i].text) \n",
    "    else: \n",
    "        continue\n",
    "  \n",
    "#Duration \n",
    "duration = soup.findAll( \n",
    "    'span', class_=\"style-scope ytd-thumbnail-overlay-time-status-renderer\") \n",
    "while len(duration) > len(titles):\n",
    "    duration.pop()\n",
    "\n",
    "d = [] \n",
    "for i in range(len(duration)): \n",
    "    if i%2 == 0 :\n",
    "        d.append(str(duration[i].text[5:9])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlwr.Workbook('Mrbeast_data.xlsx') \n",
    "worksheet = workbook.add_worksheet() \n",
    "\n",
    "worksheet.write(0, 0, \"Title\") \n",
    "worksheet.write(0, 1, \"Views\") \n",
    "worksheet.write(0, 2, \"Duration\") \n",
    "\n",
    "row = []\n",
    "row = 1\n",
    "for title, view, dura in zip(t,v,d): \n",
    "\tworksheet.write(row, 0, title) \n",
    "\tworksheet.write(row, 1, view) \n",
    "\tworksheet.write(row, 2, dura) \n",
    "\trow += 1\n",
    "\n",
    "workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Title       Views Duration\n",
      "0               $1 vs $250,000,000 Private Island!  104M views     16:5\n",
      "1                        Protect $500,000 Keep It!  104M views     15:3\n",
      "2           I Spent 7 Days In Solitary Confinement  120M views     20:1\n",
      "3                    I Rescued 100 Abandoned Dogs!  117M views     15:0\n",
      "4           Survive 100 Days Trapped, Win $500,000  167M views     27:0\n",
      "..                                             ...         ...      ...\n",
      "265    Donating $10,000 To Random Twitch Streamers   10M views     16:1\n",
      "266                               Breaking The Law   31M views     3:57\n",
      "267  Giving Homeless People $1,000 (Not Clickbait)  6.5M views     8:47\n",
      "268                We Are Better Than Dude Perfect   25M views     2:37\n",
      "269                 Every Challenge I've Ever Done  890K views     23:4\n",
      "\n",
      "[270 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70151/570887159.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_excel(\"Mrbeast_data.xlsx\")\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
